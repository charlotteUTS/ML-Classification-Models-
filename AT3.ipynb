{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer = pd.read_csv('/Users/charlotteli/Desktop/UTS/Year1 Sem2/36106 Machine Learning Algorithms and Applications - Autumn 2023/AT3/dataset/customers.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Set the path to the directory containing the transaction datasets\n",
    "directory_path = \"/Users/charlotteli/Desktop/UTS/Year1 Sem2/36106 Machine Learning Algorithms and Applications - Autumn 2023/AT3/dataset/transactions/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.listdir(directory_path)\n",
    "\n",
    "i = 0\n",
    "for trans in filename:\n",
    "    if i == 0:\n",
    "        filepath = os.path.join(directory_path, trans)\n",
    "        df = pd.read_csv(filepath, delimiter='|')\n",
    "        i += 1\n",
    "    else:\n",
    "        filepath = os.path.join(directory_path, trans)\n",
    "        df = pd.concat([df, pd.read_csv(filepath, delimiter='|')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4260904, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, customer, on='cc_num', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4260904, 24)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gas_transport' 'grocery_net' 'grocery_pos' 'personal_care'\n",
      " 'health_fitness' 'food_dining' 'home' 'entertainment' 'shopping_net'\n",
      " 'misc_net' 'misc_pos' 'kids_pets' 'shopping_pos' 'travel']\n"
     ]
    }
   ],
   "source": [
    "print(df['category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4 10  5  1  6  0 11  8  9  7 12 13]\n",
      "{2: 'entertainment', 3: 'food_dining', 4: 'gas_transport', 10: 'grocery_net', 5: 'grocery_pos', 1: 'health_fitness', 6: 'home', 0: 'kids_pets', 11: 'misc_net', 8: 'misc_pos', 9: 'personal_care', 7: 'shopping_net', 12: 'shopping_pos', 13: 'travel'}\n"
     ]
    }
   ],
   "source": [
    "# Match the category as number\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the column and transform the values\n",
    "df['category_encoded'] = label_encoder.fit_transform(df['category'])\n",
    "unique_encoded_values = df['category_encoded'].unique()\n",
    "print(unique_encoded_values)\n",
    "\n",
    "category_mapping = dict(zip(unique_encoded_values, label_encoder.classes_))\n",
    "print(category_mapping)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any duplicate\n",
    "assert df.duplicated().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cc_num              0\n",
       "gender              0\n",
       "acct_num_y          0\n",
       "dob                 0\n",
       "job                 0\n",
       "city_pop            0\n",
       "long                0\n",
       "lat                 0\n",
       "zip                 0\n",
       "state               0\n",
       "city                0\n",
       "street              0\n",
       "last                0\n",
       "acct_num_x          0\n",
       "first               0\n",
       "ssn                 0\n",
       "merch_long          0\n",
       "merch_lat           0\n",
       "merchant            0\n",
       "is_fraud            0\n",
       "amt                 0\n",
       "category            0\n",
       "unix_time           0\n",
       "trans_num           0\n",
       "category_encoded    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Null Value\n",
    "total = df.isnull().sum().sort_values(ascending=False)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_fraud'] = df['is_fraud'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender2'] = df['gender'].apply(lambda x: 0 if x == 'F' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-24 15:14:00.868350\n"
     ]
    }
   ],
   "source": [
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "today = pd.to_datetime('today')\n",
    "print(today)\n",
    "age = today - df['dob']\n",
    "df['age'] = np.round(age.dt.days / 365.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                cc_num    acct_num_x                         trans_num   \n",
      "0  4896331812335761701  149852234418  f3ec0819590302134f03ffdc2f44697f  \\\n",
      "1  4896331812335761701  149852234418  c1607c993e41f2c3b42d72d1506bef7b   \n",
      "2  4896331812335761701  149852234418  6f530db25d20fe351249a54491fd3fde   \n",
      "3  4896331812335761701  149852234418  6d11805f2acd938fec99376001afafe8   \n",
      "4  4896331812335761701  149852234418  605342f297c575cb1ccf2c08cad082ee   \n",
      "\n",
      "    unix_time       category    amt  is_fraud                     merchant   \n",
      "0  1646060228  gas_transport  65.17         0       Larson, Ryan and Huang  \\\n",
      "1  1644848624  gas_transport  47.58         0                   Myers-Reed   \n",
      "2  1645632153  gas_transport  64.43         0                Baker-Bullock   \n",
      "3  1645311286  gas_transport  82.47         0                 Spencer-Hall   \n",
      "4  1641571926  gas_transport  50.28         0  King, Rodriguez and Hancock   \n",
      "\n",
      "   merch_lat  merch_long  ...    zip      lat     long city_pop   \n",
      "0  38.143430  -90.327335  ...  62013  38.9255 -90.5968      552  \\\n",
      "1  39.119498  -90.760379  ...  62013  38.9255 -90.5968      552   \n",
      "2  39.384368  -90.361517  ...  62013  38.9255 -90.5968      552   \n",
      "3  39.443567  -89.752400  ...  62013  38.9255 -90.5968      552   \n",
      "4  38.857278  -89.609525  ...  62013  38.9255 -90.5968      552   \n",
      "\n",
      "               job        dob    acct_num_y  category_encoded  gender2   age  \n",
      "0  Patent attorney 2002-07-27  149852234418                 2        1  21.0  \n",
      "1  Patent attorney 2002-07-27  149852234418                 2        1  21.0  \n",
      "2  Patent attorney 2002-07-27  149852234418                 2        1  21.0  \n",
      "3  Patent attorney 2002-07-27  149852234418                 2        1  21.0  \n",
      "4  Patent attorney 2002-07-27  149852234418                 2        1  21.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud\n",
      "0    4255870\n",
      "1       5034\n",
      "Name: count, dtype: int64\n",
      "is_fraud\n",
      "0    99.881856\n",
      "1     0.118144\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "fraud_distribution = df['is_fraud'].value_counts()\n",
    "percentage_distribution = fraud_distribution / len(df) * 100\n",
    "print(fraud_distribution)\n",
    "print(percentage_distribution)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4260904, 7)\n",
      "(4260904,)\n"
     ]
    }
   ],
   "source": [
    "x1 = df[['is_fraud','amt', 'age', 'gender2','zip','category_encoded','merch_lat','merch_long' ]]\n",
    "y = x1.pop('is_fraud')\n",
    "print(x1.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_test, y, y_test = train_test_split(x1, y, test_size=0.1, random_state=42)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3451331, 7)\n",
      "(383482, 7)\n",
      "(426091, 7)\n",
      "(3451331,)\n",
      "(383482,)\n",
      "(426091,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.fit(x_train, y_train)\n",
    "train_preds = log_reg.predict(x_train)\n",
    "val_preds = log_reg.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9987775730580463 \n",
      "Validation Set : 0.9987352731027793\n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(accuracy_score(y_train, train_preds), accuracy_score(y_val, val_preds))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(f1_score(y_train, train_preds), f1_score(y_val, val_preds))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(recall_score(y_train, train_preds), recall_score(y_val, val_preds))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\".format(precision_score(y_train, train_preds), recall_score(y_val, val_preds))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteli/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "l2_model = LogisticRegression(penalty='l2', solver='saga').fit(x_train, y_train)\n",
    "train_preds_l2 = l2_model.predict(x_train)\n",
    "val_preds_l2 = l2_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9987958268853379 \n",
      "Validation Set : 0.9987717806833176\n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(accuracy_score(y_train, train_preds_l2), accuracy_score(y_val, val_preds_l2))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(f1_score(y_train, train_preds_l2), f1_score(y_val, val_preds_l2))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(recall_score(y_train, train_preds_l2), recall_score(y_val, val_preds_l2))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(precision_score(y_train, train_preds_l2), recall_score(y_val, val_preds_l2))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charlotteli/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='saga').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_elastic = log_reg_l1.predict(x_train)\n",
    "y_val_preds_elastic = log_reg_l1.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9987958268853379 \n",
      "Validation Set : 0.9987717806833176\n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.0 \n",
      "Validation Set : 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(accuracy_score(y_train, y_train_preds_elastic), accuracy_score(y_val, y_val_preds_elastic))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(f1_score(y_train, y_train_preds_elastic), f1_score(y_val, y_val_preds_elastic))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(recall_score(y_train, y_train_preds_elastic), recall_score(y_val, y_val_preds_elastic))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {}\\n\".format(precision_score(y_train, y_train_preds_elastic), recall_score(y_val, y_val_preds_elastic))) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_1 = DecisionTreeClassifier(random_state=8).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = tree_1.predict(x_train)\n",
    "y_val_preds = tree_1.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 1.0 \n",
      "Validation Set : 0.9980859597060618 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 1.0 \n",
      "Validation Set : 0.25858585858585864 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 1.0 \n",
      "Validation Set : 0.27645788336933047 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 1.0 \n",
      "Validation Set : 0.2428842504743833 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_preds), accuracy_score(y_val, y_val_preds))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_preds),f1_score(y_val, y_val_preds))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_preds), recall_score(y_val, y_val_preds))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_preds), precision_score(y_val, y_val_preds))) \n",
    "\n",
    "# The difference in performance between the training and validation sets is huge, indicating that the model is overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce Overfitting with min_samples_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_split=20\n",
    "tree_2 = DecisionTreeClassifier(random_state=8, min_samples_split=20).fit(x_train, y_train)\n",
    "y_train_preds2 = tree_2.predict(x_train)\n",
    "y_val_preds2 = tree_2.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9993683596270541 \n",
      "Validation Set : 0.9985240506725218 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.6836912362159026 \n",
      "Validation Set : 0.3046683046683047 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.5756169069142438 \n",
      "Validation Set : 0.2678185745140389 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.8417291889960701 \n",
      "Validation Set : 0.35327635327635326 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_preds2), accuracy_score(y_val, y_val_preds2))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_preds2),f1_score(y_val, y_val_preds2))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_preds2), recall_score(y_val, y_val_preds2))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_preds2), precision_score(y_val, y_val_preds2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_split=30\n",
    "tree_3 = DecisionTreeClassifier(random_state=8, min_samples_split=30).fit(x_train, y_train)\n",
    "y_train_preds3 = tree_3.predict(x_train)\n",
    "y_val_preds3 = tree_3.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9992770904905962 \n",
      "Validation Set : 0.9986205349925159 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.6233962264150943 \n",
      "Validation Set : 0.31741935483870964 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.5045199120449548 \n",
      "Validation Set : 0.265658747300216 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.8155608214849921 \n",
      "Validation Set : 0.3942307692307692 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_preds3), accuracy_score(y_val, y_val_preds3))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_preds3),f1_score(y_val, y_val_preds3))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_preds3), recall_score(y_val, y_val_preds3))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_preds3), precision_score(y_val, y_val_preds3))) \n",
    "\n",
    "# The difference in performance between the training and validation sets is large, indicating that the model still is overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce Overfitting with max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_3.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_split=30 and max_depth=10\n",
    "tree_depth = DecisionTreeClassifier(random_state=8, min_samples_split=30, max_depth=10).fit(x_train, y_train)\n",
    "y_train_preds4 = tree_depth.predict(x_train)\n",
    "y_val_preds4 = tree_depth.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9989916933496091 \n",
      "Validation Set : 0.9988161113168285 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.39075630252100835 \n",
      "Validation Set : 0.30153846153846153 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.27266064011727337 \n",
      "Validation Set : 0.21166306695464362 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.6893143915997529 \n",
      "Validation Set : 0.5240641711229946 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_preds4), accuracy_score(y_val, y_val_preds4))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_preds4),f1_score(y_val, y_val_preds4))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_preds4), recall_score(y_val, y_val_preds4))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_preds4), precision_score(y_val, y_val_preds4))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_samples_split=15 and max_depth=20\n",
    "tree_depth2 = DecisionTreeClassifier(random_state=8, min_samples_split=15, max_depth=20).fit(x_train, y_train)\n",
    "y_train_preds5 = tree_depth.predict(x_train)\n",
    "y_val_preds5 = tree_depth.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9989916933496091 \n",
      "Validation Set : 0.9988161113168285 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.39075630252100835 \n",
      "Validation Set : 0.30153846153846153 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.27266064011727337 \n",
      "Validation Set : 0.21166306695464362 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.6893143915997529 \n",
      "Validation Set : 0.5240641711229946 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_preds5), accuracy_score(y_val, y_val_preds5))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_preds5),f1_score(y_val, y_val_preds5))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_preds5), recall_score(y_val, y_val_preds5))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_preds5), precision_score(y_val, y_val_preds5))) \n",
    "\n",
    "# The result is the same as the previous model with max_depth=10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess Decision Tree model on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = tree_depth2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: \n",
      "\n",
      "Accuracy  score : 0.9985988908472603 \n",
      "f1 score : 0.2546816479400749 \n",
      "Recall score : 0.21338912133891214 \n",
      "Precision score : 0.3157894736842105 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: \\n\")\n",
    "print(\"Accuracy  score : {} \\nf1 score : {} \\nRecall score : {} \\nPrecision score : {} \\n\".format(accuracy_score(y_test, y_test_preds), f1_score(y_test, y_test_preds), recall_score(y_test, y_test_preds), precision_score(y_test, y_test_preds))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a binary tree model with randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=8,min_samples_split=30,max_depth=20).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rfpreds = rf.predict(x_train)\n",
    "y_val_rfpreds = rf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9990794855665829 \n",
      "Validation Set : 0.9989152033211468 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.3891559315516247 \n",
      "Validation Set : 0.26501766784452296 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.2472514048375275 \n",
      "Validation Set : 0.16198704103671707 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.9133574007220217 \n",
      "Validation Set : 0.7281553398058253 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_rfpreds), accuracy_score(y_val, y_val_rfpreds))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_rfpreds),f1_score(y_val, y_val_rfpreds))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_rfpreds), recall_score(y_val, y_val_rfpreds))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_rfpreds), precision_score(y_val, y_val_rfpreds))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(random_state=8, min_samples_split=30,max_depth=20, n_estimators=50).fit(x_train, y_train)\n",
    "y_train_preds2 = rf2.predict(x_train)\n",
    "y_val_preds2 = rf2.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: \n",
      "\n",
      "Training set : 0.9990783265934214 \n",
      "Validation Set : 0.9989099879524984 \n",
      "\n",
      "f1 score: \n",
      "\n",
      "Training set : 0.3911961722488038 \n",
      "Validation Set : 0.2535714285714285 \n",
      "\n",
      "Recall score: \n",
      "\n",
      "Training set : 0.24969460053750306 \n",
      "Validation Set : 0.15334773218142547 \n",
      "\n",
      "Precision score: \n",
      "\n",
      "Training set : 0.9028268551236749 \n",
      "Validation Set : 0.7319587628865979 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(accuracy_score(y_train, y_train_preds2), accuracy_score(y_val, y_val_preds2))) \n",
    "\n",
    "print(\"f1 score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(f1_score(y_train, y_train_preds2),f1_score(y_val, y_val_preds2))) \n",
    "\n",
    "print(\"Recall score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(recall_score(y_train, y_train_preds2), recall_score(y_val, y_val_preds2))) \n",
    "\n",
    "print(\"Precision score: \\n\")\n",
    "print(\"Training set : {} \\nValidation Set : {} \\n\".format(precision_score(y_train, y_train_preds2), precision_score(y_val, y_val_preds2))) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assess model on Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds2 = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: \n",
      "\n",
      "Accuracy  score : 0.9989650098218456 \n",
      "f1 score : 0.2276707530647986 \n",
      "Recall score : 0.13598326359832635 \n",
      "Precision score : 0.6989247311827957 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: \\n\")\n",
    "print(\"Accuracy  score : {} \\nf1 score : {} \\nRecall score : {} \\nPrecision score : {} \\n\".format(accuracy_score(y_test, y_test_preds2), f1_score(y_test, y_test_preds2), recall_score(y_test, y_test_preds2), precision_score(y_test, y_test_preds2))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
